{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Predict price after pattern.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOYi/Z1JW4rDyb8fhXmuFhc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/romqn1999/Predict-price-after-pattern/blob/main/Predict_price_after_pattern.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7CgpmdW5jdGlvbiBfdXBsb2FkRmlsZXMoaW5wdXRJZCwgb3V0cHV0SWQpIHsKICBjb25zdCBzdGVwcyA9IHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCk7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICAvLyBDYWNoZSBzdGVwcyBvbiB0aGUgb3V0cHV0RWxlbWVudCB0byBtYWtlIGl0IGF2YWlsYWJsZSBmb3IgdGhlIG5leHQgY2FsbAogIC8vIHRvIHVwbG9hZEZpbGVzQ29udGludWUgZnJvbSBQeXRob24uCiAgb3V0cHV0RWxlbWVudC5zdGVwcyA9IHN0ZXBzOwoKICByZXR1cm4gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpOwp9CgovLyBUaGlzIGlzIHJvdWdobHkgYW4gYXN5bmMgZ2VuZXJhdG9yIChub3Qgc3VwcG9ydGVkIGluIHRoZSBicm93c2VyIHlldCksCi8vIHdoZXJlIHRoZXJlIGFyZSBtdWx0aXBsZSBhc3luY2hyb25vdXMgc3RlcHMgYW5kIHRoZSBQeXRob24gc2lkZSBpcyBnb2luZwovLyB0byBwb2xsIGZvciBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcC4KLy8gVGhpcyB1c2VzIGEgUHJvbWlzZSB0byBibG9jayB0aGUgcHl0aG9uIHNpZGUgb24gY29tcGxldGlvbiBvZiBlYWNoIHN0ZXAsCi8vIHRoZW4gcGFzc2VzIHRoZSByZXN1bHQgb2YgdGhlIHByZXZpb3VzIHN0ZXAgYXMgdGhlIGlucHV0IHRvIHRoZSBuZXh0IHN0ZXAuCmZ1bmN0aW9uIF91cGxvYWRGaWxlc0NvbnRpbnVlKG91dHB1dElkKSB7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICBjb25zdCBzdGVwcyA9IG91dHB1dEVsZW1lbnQuc3RlcHM7CgogIGNvbnN0IG5leHQgPSBzdGVwcy5uZXh0KG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSk7CiAgcmV0dXJuIFByb21pc2UucmVzb2x2ZShuZXh0LnZhbHVlLnByb21pc2UpLnRoZW4oKHZhbHVlKSA9PiB7CiAgICAvLyBDYWNoZSB0aGUgbGFzdCBwcm9taXNlIHZhbHVlIHRvIG1ha2UgaXQgYXZhaWxhYmxlIHRvIHRoZSBuZXh0CiAgICAvLyBzdGVwIG9mIHRoZSBnZW5lcmF0b3IuCiAgICBvdXRwdXRFbGVtZW50Lmxhc3RQcm9taXNlVmFsdWUgPSB2YWx1ZTsKICAgIHJldHVybiBuZXh0LnZhbHVlLnJlc3BvbnNlOwogIH0pOwp9CgovKioKICogR2VuZXJhdG9yIGZ1bmN0aW9uIHdoaWNoIGlzIGNhbGxlZCBiZXR3ZWVuIGVhY2ggYXN5bmMgc3RlcCBvZiB0aGUgdXBsb2FkCiAqIHByb2Nlc3MuCiAqIEBwYXJhbSB7c3RyaW5nfSBpbnB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIGlucHV0IGZpbGUgcGlja2VyIGVsZW1lbnQuCiAqIEBwYXJhbSB7c3RyaW5nfSBvdXRwdXRJZCBFbGVtZW50IElEIG9mIHRoZSBvdXRwdXQgZGlzcGxheS4KICogQHJldHVybiB7IUl0ZXJhYmxlPCFPYmplY3Q+fSBJdGVyYWJsZSBvZiBuZXh0IHN0ZXBzLgogKi8KZnVuY3Rpb24qIHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IGlucHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKGlucHV0SWQpOwogIGlucHV0RWxlbWVudC5kaXNhYmxlZCA9IGZhbHNlOwoKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIG91dHB1dEVsZW1lbnQuaW5uZXJIVE1MID0gJyc7CgogIGNvbnN0IHBpY2tlZFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgaW5wdXRFbGVtZW50LmFkZEV2ZW50TGlzdGVuZXIoJ2NoYW5nZScsIChlKSA9PiB7CiAgICAgIHJlc29sdmUoZS50YXJnZXQuZmlsZXMpOwogICAgfSk7CiAgfSk7CgogIGNvbnN0IGNhbmNlbCA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2J1dHRvbicpOwogIGlucHV0RWxlbWVudC5wYXJlbnRFbGVtZW50LmFwcGVuZENoaWxkKGNhbmNlbCk7CiAgY2FuY2VsLnRleHRDb250ZW50ID0gJ0NhbmNlbCB1cGxvYWQnOwogIGNvbnN0IGNhbmNlbFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgY2FuY2VsLm9uY2xpY2sgPSAoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9OwogIH0pOwoKICAvLyBXYWl0IGZvciB0aGUgdXNlciB0byBwaWNrIHRoZSBmaWxlcy4KICBjb25zdCBmaWxlcyA9IHlpZWxkIHsKICAgIHByb21pc2U6IFByb21pc2UucmFjZShbcGlja2VkUHJvbWlzZSwgY2FuY2VsUHJvbWlzZV0pLAogICAgcmVzcG9uc2U6IHsKICAgICAgYWN0aW9uOiAnc3RhcnRpbmcnLAogICAgfQogIH07CgogIGNhbmNlbC5yZW1vdmUoKTsKCiAgLy8gRGlzYWJsZSB0aGUgaW5wdXQgZWxlbWVudCBzaW5jZSBmdXJ0aGVyIHBpY2tzIGFyZSBub3QgYWxsb3dlZC4KICBpbnB1dEVsZW1lbnQuZGlzYWJsZWQgPSB0cnVlOwoKICBpZiAoIWZpbGVzKSB7CiAgICByZXR1cm4gewogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgICAgfQogICAgfTsKICB9CgogIGZvciAoY29uc3QgZmlsZSBvZiBmaWxlcykgewogICAgY29uc3QgbGkgPSBkb2N1bWVudC5jcmVhdGVFbGVtZW50KCdsaScpOwogICAgbGkuYXBwZW5kKHNwYW4oZmlsZS5uYW1lLCB7Zm9udFdlaWdodDogJ2JvbGQnfSkpOwogICAgbGkuYXBwZW5kKHNwYW4oCiAgICAgICAgYCgke2ZpbGUudHlwZSB8fCAnbi9hJ30pIC0gJHtmaWxlLnNpemV9IGJ5dGVzLCBgICsKICAgICAgICBgbGFzdCBtb2RpZmllZDogJHsKICAgICAgICAgICAgZmlsZS5sYXN0TW9kaWZpZWREYXRlID8gZmlsZS5sYXN0TW9kaWZpZWREYXRlLnRvTG9jYWxlRGF0ZVN0cmluZygpIDoKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgJ24vYSd9IC0gYCkpOwogICAgY29uc3QgcGVyY2VudCA9IHNwYW4oJzAlIGRvbmUnKTsKICAgIGxpLmFwcGVuZENoaWxkKHBlcmNlbnQpOwoKICAgIG91dHB1dEVsZW1lbnQuYXBwZW5kQ2hpbGQobGkpOwoKICAgIGNvbnN0IGZpbGVEYXRhUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICAgIGNvbnN0IHJlYWRlciA9IG5ldyBGaWxlUmVhZGVyKCk7CiAgICAgIHJlYWRlci5vbmxvYWQgPSAoZSkgPT4gewogICAgICAgIHJlc29sdmUoZS50YXJnZXQucmVzdWx0KTsKICAgICAgfTsKICAgICAgcmVhZGVyLnJlYWRBc0FycmF5QnVmZmVyKGZpbGUpOwogICAgfSk7CiAgICAvLyBXYWl0IGZvciB0aGUgZGF0YSB0byBiZSByZWFkeS4KICAgIGxldCBmaWxlRGF0YSA9IHlpZWxkIHsKICAgICAgcHJvbWlzZTogZmlsZURhdGFQcm9taXNlLAogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbnRpbnVlJywKICAgICAgfQogICAgfTsKCiAgICAvLyBVc2UgYSBjaHVua2VkIHNlbmRpbmcgdG8gYXZvaWQgbWVzc2FnZSBzaXplIGxpbWl0cy4gU2VlIGIvNjIxMTU2NjAuCiAgICBsZXQgcG9zaXRpb24gPSAwOwogICAgd2hpbGUgKHBvc2l0aW9uIDwgZmlsZURhdGEuYnl0ZUxlbmd0aCkgewogICAgICBjb25zdCBsZW5ndGggPSBNYXRoLm1pbihmaWxlRGF0YS5ieXRlTGVuZ3RoIC0gcG9zaXRpb24sIE1BWF9QQVlMT0FEX1NJWkUpOwogICAgICBjb25zdCBjaHVuayA9IG5ldyBVaW50OEFycmF5KGZpbGVEYXRhLCBwb3NpdGlvbiwgbGVuZ3RoKTsKICAgICAgcG9zaXRpb24gKz0gbGVuZ3RoOwoKICAgICAgY29uc3QgYmFzZTY0ID0gYnRvYShTdHJpbmcuZnJvbUNoYXJDb2RlLmFwcGx5KG51bGwsIGNodW5rKSk7CiAgICAgIHlpZWxkIHsKICAgICAgICByZXNwb25zZTogewogICAgICAgICAgYWN0aW9uOiAnYXBwZW5kJywKICAgICAgICAgIGZpbGU6IGZpbGUubmFtZSwKICAgICAgICAgIGRhdGE6IGJhc2U2NCwKICAgICAgICB9LAogICAgICB9OwogICAgICBwZXJjZW50LnRleHRDb250ZW50ID0KICAgICAgICAgIGAke01hdGgucm91bmQoKHBvc2l0aW9uIC8gZmlsZURhdGEuYnl0ZUxlbmd0aCkgKiAxMDApfSUgZG9uZWA7CiAgICB9CiAgfQoKICAvLyBBbGwgZG9uZS4KICB5aWVsZCB7CiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICB9CiAgfTsKfQoKc2NvcGUuZ29vZ2xlID0gc2NvcGUuZ29vZ2xlIHx8IHt9OwpzY29wZS5nb29nbGUuY29sYWIgPSBzY29wZS5nb29nbGUuY29sYWIgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYi5fZmlsZXMgPSB7CiAgX3VwbG9hZEZpbGVzLAogIF91cGxvYWRGaWxlc0NvbnRpbnVlLAp9Owp9KShzZWxmKTsK",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "JkUOuKONzqJx",
        "outputId": "7fa72679-99c9-41e7-a452-6614f56c0853"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8066d5a8-b45f-40f5-b338-a7e22108b387\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-8066d5a8-b45f-40f5-b338-a7e22108b387\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving AAPL_2000-01-01 00_00_00_2021-05-17_30_data_patterns.csv to AAPL_2000-01-01 00_00_00_2021-05-17_30_data_patterns (1).csv\n",
            "Saving GOOG_2000-01-01 00_00_00_2021-05-17_30_data_patterns.csv to GOOG_2000-01-01 00_00_00_2021-05-17_30_data_patterns.csv\n",
            "Saving SNP_2000-01-01 00_00_00_2021-05-17_30_data_patterns.csv to SNP_2000-01-01 00_00_00_2021-05-17_30_data_patterns (4).csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "no8aDSVlApbi"
      },
      "source": [
        "## Import packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NN2ViWdt_Mxc"
      },
      "source": [
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import *\n",
        "from keras import optimizers\n",
        "from keras.optimizers import Adagrad, Adadelta, RMSprop, Adam\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.callbacks import EarlyStopping"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9fE_16D7ZPO"
      },
      "source": [
        "## Get data at pattern for training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "zrT35S6m0GZB",
        "outputId": "504cf2b6-66f4-492d-effd-354c1a3b4ac9"
      },
      "source": [
        "import io\n",
        "import pandas as pd\n",
        "\n",
        "price_patterns_df = pd.DataFrame()\n",
        "for filename in uploaded.keys():\n",
        "    print(filename)\n",
        "    if 'data_patterns.csv' not in filename:\n",
        "        print('Skipping file', filename)\n",
        "        continue\n",
        "    df = pd.read_csv(io.StringIO(uploaded[filename].decode('utf-8')),\n",
        "                     header=None)\n",
        "    price_patterns_df = price_patterns_df.append(df)\n",
        "\n",
        "price_patterns_df"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AAPL_2000-01-01 00_00_00_2021-05-17_30_data_patterns.csv\n",
            "GOOG_2000-01-01 00_00_00_2021-05-17_30_data_patterns.csv\n",
            "SNP_2000-01-01 00_00_00_2021-05-17_30_data_patterns.csv\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.032500</td>\n",
              "      <td>4.680357</td>\n",
              "      <td>4.530000</td>\n",
              "      <td>4.596786</td>\n",
              "      <td>4.711786</td>\n",
              "      <td>4.580000</td>\n",
              "      <td>3.759286</td>\n",
              "      <td>4.059286</td>\n",
              "      <td>3.897143</td>\n",
              "      <td>3.575000</td>\n",
              "      <td>3.466786</td>\n",
              "      <td>3.505000</td>\n",
              "      <td>3.184286</td>\n",
              "      <td>3.206786</td>\n",
              "      <td>3.169286</td>\n",
              "      <td>3.457143</td>\n",
              "      <td>3.937857</td>\n",
              "      <td>3.717143</td>\n",
              "      <td>3.498214</td>\n",
              "      <td>3.638929</td>\n",
              "      <td>3.478571</td>\n",
              "      <td>3.515714</td>\n",
              "      <td>3.267500</td>\n",
              "      <td>3.459643</td>\n",
              "      <td>3.508214</td>\n",
              "      <td>3.442143</td>\n",
              "      <td>3.288929</td>\n",
              "      <td>3.568214</td>\n",
              "      <td>3.733929</td>\n",
              "      <td>3.965714</td>\n",
              "      <td>3.842500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3.575000</td>\n",
              "      <td>3.466786</td>\n",
              "      <td>3.505000</td>\n",
              "      <td>3.184286</td>\n",
              "      <td>3.206786</td>\n",
              "      <td>3.169286</td>\n",
              "      <td>3.457143</td>\n",
              "      <td>3.937857</td>\n",
              "      <td>3.717143</td>\n",
              "      <td>3.498214</td>\n",
              "      <td>3.638929</td>\n",
              "      <td>3.478571</td>\n",
              "      <td>3.515714</td>\n",
              "      <td>3.267500</td>\n",
              "      <td>3.459643</td>\n",
              "      <td>3.508214</td>\n",
              "      <td>3.442143</td>\n",
              "      <td>3.288929</td>\n",
              "      <td>3.568214</td>\n",
              "      <td>3.733929</td>\n",
              "      <td>3.965714</td>\n",
              "      <td>3.842500</td>\n",
              "      <td>3.820000</td>\n",
              "      <td>3.963929</td>\n",
              "      <td>3.689286</td>\n",
              "      <td>3.539286</td>\n",
              "      <td>3.508571</td>\n",
              "      <td>3.424286</td>\n",
              "      <td>3.384643</td>\n",
              "      <td>3.218571</td>\n",
              "      <td>3.444286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.064643</td>\n",
              "      <td>3.093214</td>\n",
              "      <td>3.081786</td>\n",
              "      <td>3.048214</td>\n",
              "      <td>3.241071</td>\n",
              "      <td>3.377857</td>\n",
              "      <td>3.322143</td>\n",
              "      <td>3.250357</td>\n",
              "      <td>3.310714</td>\n",
              "      <td>3.235000</td>\n",
              "      <td>3.166429</td>\n",
              "      <td>3.132500</td>\n",
              "      <td>3.047500</td>\n",
              "      <td>2.977857</td>\n",
              "      <td>2.940357</td>\n",
              "      <td>2.792857</td>\n",
              "      <td>2.958214</td>\n",
              "      <td>3.155714</td>\n",
              "      <td>3.155714</td>\n",
              "      <td>3.201429</td>\n",
              "      <td>3.240357</td>\n",
              "      <td>3.364286</td>\n",
              "      <td>3.321429</td>\n",
              "      <td>3.218929</td>\n",
              "      <td>3.268214</td>\n",
              "      <td>3.320714</td>\n",
              "      <td>3.341071</td>\n",
              "      <td>3.445000</td>\n",
              "      <td>3.561429</td>\n",
              "      <td>3.661071</td>\n",
              "      <td>3.493929</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.064643</td>\n",
              "      <td>3.093214</td>\n",
              "      <td>3.081786</td>\n",
              "      <td>3.048214</td>\n",
              "      <td>3.241071</td>\n",
              "      <td>3.377857</td>\n",
              "      <td>3.322143</td>\n",
              "      <td>3.250357</td>\n",
              "      <td>3.310714</td>\n",
              "      <td>3.235000</td>\n",
              "      <td>3.166429</td>\n",
              "      <td>3.132500</td>\n",
              "      <td>3.047500</td>\n",
              "      <td>2.977857</td>\n",
              "      <td>2.940357</td>\n",
              "      <td>2.792857</td>\n",
              "      <td>2.958214</td>\n",
              "      <td>3.155714</td>\n",
              "      <td>3.155714</td>\n",
              "      <td>3.201429</td>\n",
              "      <td>3.240357</td>\n",
              "      <td>3.364286</td>\n",
              "      <td>3.321429</td>\n",
              "      <td>3.218929</td>\n",
              "      <td>3.268214</td>\n",
              "      <td>3.320714</td>\n",
              "      <td>3.341071</td>\n",
              "      <td>3.445000</td>\n",
              "      <td>3.561429</td>\n",
              "      <td>3.661071</td>\n",
              "      <td>3.493929</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3.064643</td>\n",
              "      <td>3.093214</td>\n",
              "      <td>3.081786</td>\n",
              "      <td>3.048214</td>\n",
              "      <td>3.241071</td>\n",
              "      <td>3.377857</td>\n",
              "      <td>3.322143</td>\n",
              "      <td>3.250357</td>\n",
              "      <td>3.310714</td>\n",
              "      <td>3.235000</td>\n",
              "      <td>3.166429</td>\n",
              "      <td>3.132500</td>\n",
              "      <td>3.047500</td>\n",
              "      <td>2.977857</td>\n",
              "      <td>2.940357</td>\n",
              "      <td>2.792857</td>\n",
              "      <td>2.958214</td>\n",
              "      <td>3.155714</td>\n",
              "      <td>3.155714</td>\n",
              "      <td>3.201429</td>\n",
              "      <td>3.240357</td>\n",
              "      <td>3.364286</td>\n",
              "      <td>3.321429</td>\n",
              "      <td>3.218929</td>\n",
              "      <td>3.268214</td>\n",
              "      <td>3.320714</td>\n",
              "      <td>3.341071</td>\n",
              "      <td>3.445000</td>\n",
              "      <td>3.561429</td>\n",
              "      <td>3.661071</td>\n",
              "      <td>3.493929</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>45.930000</td>\n",
              "      <td>45.889999</td>\n",
              "      <td>46.200001</td>\n",
              "      <td>44.560001</td>\n",
              "      <td>45.080002</td>\n",
              "      <td>45.880001</td>\n",
              "      <td>45.049999</td>\n",
              "      <td>44.430000</td>\n",
              "      <td>43.599998</td>\n",
              "      <td>43.959999</td>\n",
              "      <td>44.540001</td>\n",
              "      <td>44.259998</td>\n",
              "      <td>43.799999</td>\n",
              "      <td>43.750000</td>\n",
              "      <td>43.480000</td>\n",
              "      <td>43.619999</td>\n",
              "      <td>43.480000</td>\n",
              "      <td>43.500000</td>\n",
              "      <td>42.959999</td>\n",
              "      <td>42.279999</td>\n",
              "      <td>41.540001</td>\n",
              "      <td>40.470001</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>40.389999</td>\n",
              "      <td>40.549999</td>\n",
              "      <td>40.240002</td>\n",
              "      <td>40.459999</td>\n",
              "      <td>40.310001</td>\n",
              "      <td>40.029999</td>\n",
              "      <td>40.810001</td>\n",
              "      <td>40.849998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>44.430000</td>\n",
              "      <td>43.599998</td>\n",
              "      <td>43.959999</td>\n",
              "      <td>44.540001</td>\n",
              "      <td>44.259998</td>\n",
              "      <td>43.799999</td>\n",
              "      <td>43.750000</td>\n",
              "      <td>43.480000</td>\n",
              "      <td>43.619999</td>\n",
              "      <td>43.480000</td>\n",
              "      <td>43.500000</td>\n",
              "      <td>42.959999</td>\n",
              "      <td>42.279999</td>\n",
              "      <td>41.540001</td>\n",
              "      <td>40.470001</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>40.389999</td>\n",
              "      <td>40.549999</td>\n",
              "      <td>40.240002</td>\n",
              "      <td>40.459999</td>\n",
              "      <td>40.310001</td>\n",
              "      <td>40.029999</td>\n",
              "      <td>40.810001</td>\n",
              "      <td>40.849998</td>\n",
              "      <td>41.049999</td>\n",
              "      <td>41.389999</td>\n",
              "      <td>40.880001</td>\n",
              "      <td>41.320000</td>\n",
              "      <td>41.459999</td>\n",
              "      <td>39.169998</td>\n",
              "      <td>38.970001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>45.570000</td>\n",
              "      <td>46.869999</td>\n",
              "      <td>47.040001</td>\n",
              "      <td>46.230000</td>\n",
              "      <td>46.049999</td>\n",
              "      <td>45.570000</td>\n",
              "      <td>46.410000</td>\n",
              "      <td>46.720001</td>\n",
              "      <td>47.490002</td>\n",
              "      <td>48.099998</td>\n",
              "      <td>45.080002</td>\n",
              "      <td>45.639999</td>\n",
              "      <td>47.180000</td>\n",
              "      <td>46.560001</td>\n",
              "      <td>46.139999</td>\n",
              "      <td>45.910000</td>\n",
              "      <td>43.939999</td>\n",
              "      <td>43.130001</td>\n",
              "      <td>43.349998</td>\n",
              "      <td>44.259998</td>\n",
              "      <td>44.099998</td>\n",
              "      <td>44.270000</td>\n",
              "      <td>44.389999</td>\n",
              "      <td>44.580002</td>\n",
              "      <td>44.910000</td>\n",
              "      <td>43.820000</td>\n",
              "      <td>43.310001</td>\n",
              "      <td>43.700001</td>\n",
              "      <td>44.439999</td>\n",
              "      <td>45.160000</td>\n",
              "      <td>45.049999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150</th>\n",
              "      <td>57.490002</td>\n",
              "      <td>57.119999</td>\n",
              "      <td>55.020000</td>\n",
              "      <td>54.919998</td>\n",
              "      <td>53.779999</td>\n",
              "      <td>55.599998</td>\n",
              "      <td>55.880001</td>\n",
              "      <td>57.200001</td>\n",
              "      <td>57.410000</td>\n",
              "      <td>56.349998</td>\n",
              "      <td>55.669998</td>\n",
              "      <td>56.080002</td>\n",
              "      <td>56.090000</td>\n",
              "      <td>57.650002</td>\n",
              "      <td>57.349998</td>\n",
              "      <td>56.410000</td>\n",
              "      <td>54.470001</td>\n",
              "      <td>53.290001</td>\n",
              "      <td>52.790001</td>\n",
              "      <td>51.959999</td>\n",
              "      <td>52.270000</td>\n",
              "      <td>51.560001</td>\n",
              "      <td>53.080002</td>\n",
              "      <td>53.759998</td>\n",
              "      <td>53.490002</td>\n",
              "      <td>52.730000</td>\n",
              "      <td>53.720001</td>\n",
              "      <td>52.840000</td>\n",
              "      <td>52.919998</td>\n",
              "      <td>52.430000</td>\n",
              "      <td>52.669998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151</th>\n",
              "      <td>56.349998</td>\n",
              "      <td>55.669998</td>\n",
              "      <td>56.080002</td>\n",
              "      <td>56.090000</td>\n",
              "      <td>57.650002</td>\n",
              "      <td>57.349998</td>\n",
              "      <td>56.410000</td>\n",
              "      <td>54.470001</td>\n",
              "      <td>53.290001</td>\n",
              "      <td>52.790001</td>\n",
              "      <td>51.959999</td>\n",
              "      <td>52.270000</td>\n",
              "      <td>51.560001</td>\n",
              "      <td>53.080002</td>\n",
              "      <td>53.759998</td>\n",
              "      <td>53.490002</td>\n",
              "      <td>52.730000</td>\n",
              "      <td>53.720001</td>\n",
              "      <td>52.840000</td>\n",
              "      <td>52.919998</td>\n",
              "      <td>52.430000</td>\n",
              "      <td>52.669998</td>\n",
              "      <td>51.799999</td>\n",
              "      <td>52.250000</td>\n",
              "      <td>53.630001</td>\n",
              "      <td>54.840000</td>\n",
              "      <td>54.119999</td>\n",
              "      <td>54.709999</td>\n",
              "      <td>54.880001</td>\n",
              "      <td>53.330002</td>\n",
              "      <td>51.470001</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>304 rows × 31 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            0          1          2   ...         28         29         30\n",
              "0     5.032500   4.680357   4.530000  ...   3.733929   3.965714   3.842500\n",
              "1     3.575000   3.466786   3.505000  ...   3.384643   3.218571   3.444286\n",
              "2     3.064643   3.093214   3.081786  ...   3.561429   3.661071   3.493929\n",
              "3     3.064643   3.093214   3.081786  ...   3.561429   3.661071   3.493929\n",
              "4     3.064643   3.093214   3.081786  ...   3.561429   3.661071   3.493929\n",
              "..         ...        ...        ...  ...        ...        ...        ...\n",
              "147  45.930000  45.889999  46.200001  ...  40.029999  40.810001  40.849998\n",
              "148  44.430000  43.599998  43.959999  ...  41.459999  39.169998  38.970001\n",
              "149  45.570000  46.869999  47.040001  ...  44.439999  45.160000  45.049999\n",
              "150  57.490002  57.119999  55.020000  ...  52.919998  52.430000  52.669998\n",
              "151  56.349998  55.669998  56.080002  ...  54.880001  53.330002  51.470001\n",
              "\n",
              "[304 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3AloVK100Vr",
        "outputId": "078fc1cc-fa4d-4b63-9651-16a750830267"
      },
      "source": [
        "#@title Separate into input and output columns: Get data: X and y\n",
        "\n",
        "X_df = price_patterns_df[price_patterns_df.columns[:-1]]\n",
        "y_df = price_patterns_df[price_patterns_df.columns[-1:]]\n",
        "print(X_df)\n",
        "print(y_df)\n",
        "\n",
        "X_data = X_df.values\n",
        "y_data = y_df.values\n",
        "print(X_data)\n",
        "print(y_data)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "            0          1          2   ...         27         28         29\n",
            "0     5.032500   4.680357   4.530000  ...   3.568214   3.733929   3.965714\n",
            "1     3.575000   3.466786   3.505000  ...   3.424286   3.384643   3.218571\n",
            "2     3.064643   3.093214   3.081786  ...   3.445000   3.561429   3.661071\n",
            "3     3.064643   3.093214   3.081786  ...   3.445000   3.561429   3.661071\n",
            "4     3.064643   3.093214   3.081786  ...   3.445000   3.561429   3.661071\n",
            "..         ...        ...        ...  ...        ...        ...        ...\n",
            "147  45.930000  45.889999  46.200001  ...  40.310001  40.029999  40.810001\n",
            "148  44.430000  43.599998  43.959999  ...  41.320000  41.459999  39.169998\n",
            "149  45.570000  46.869999  47.040001  ...  43.700001  44.439999  45.160000\n",
            "150  57.490002  57.119999  55.020000  ...  52.840000  52.919998  52.430000\n",
            "151  56.349998  55.669998  56.080002  ...  54.709999  54.880001  53.330002\n",
            "\n",
            "[304 rows x 30 columns]\n",
            "            30\n",
            "0     3.842500\n",
            "1     3.444286\n",
            "2     3.493929\n",
            "3     3.493929\n",
            "4     3.493929\n",
            "..         ...\n",
            "147  40.849998\n",
            "148  38.970001\n",
            "149  45.049999\n",
            "150  52.669998\n",
            "151  51.470001\n",
            "\n",
            "[304 rows x 1 columns]\n",
            "[[5.03 4.68 4.53 ... 3.57 3.73 3.97]\n",
            " [3.58 3.47 3.51 ... 3.42 3.38 3.22]\n",
            " [3.06 3.09 3.08 ... 3.44 3.56 3.66]\n",
            " ...\n",
            " [45.57 46.87 47.04 ... 43.70 44.44 45.16]\n",
            " [57.49 57.12 55.02 ... 52.84 52.92 52.43]\n",
            " [56.35 55.67 56.08 ... 54.71 54.88 53.33]]\n",
            "[[3.84]\n",
            " [3.44]\n",
            " [3.49]\n",
            " [3.49]\n",
            " [3.49]\n",
            " [3.80]\n",
            " [3.80]\n",
            " [3.80]\n",
            " [3.80]\n",
            " [4.14]\n",
            " [4.14]\n",
            " [4.14]\n",
            " [4.14]\n",
            " [9.40]\n",
            " [9.71]\n",
            " [9.71]\n",
            " [8.67]\n",
            " [8.67]\n",
            " [8.67]\n",
            " [9.57]\n",
            " [9.57]\n",
            " [11.02]\n",
            " [11.95]\n",
            " [11.95]\n",
            " [11.85]\n",
            " [12.52]\n",
            " [12.52]\n",
            " [12.52]\n",
            " [11.87]\n",
            " [11.66]\n",
            " [11.66]\n",
            " [11.66]\n",
            " [11.66]\n",
            " [11.66]\n",
            " [11.66]\n",
            " [12.56]\n",
            " [12.85]\n",
            " [12.85]\n",
            " [13.93]\n",
            " [13.93]\n",
            " [13.45]\n",
            " [14.16]\n",
            " [20.53]\n",
            " [19.36]\n",
            " [19.36]\n",
            " [15.37]\n",
            " [14.89]\n",
            " [14.89]\n",
            " [14.89]\n",
            " [16.88]\n",
            " [16.88]\n",
            " [19.43]\n",
            " [19.43]\n",
            " [25.19]\n",
            " [25.19]\n",
            " [25.25]\n",
            " [24.39]\n",
            " [24.39]\n",
            " [25.75]\n",
            " [28.25]\n",
            " [31.50]\n",
            " [31.73]\n",
            " [32.42]\n",
            " [32.42]\n",
            " [32.42]\n",
            " [32.19]\n",
            " [32.16]\n",
            " [31.36]\n",
            " [28.55]\n",
            " [28.55]\n",
            " [28.12]\n",
            " [24.17]\n",
            " [24.86]\n",
            " [23.75]\n",
            " [24.53]\n",
            " [24.07]\n",
            " [24.07]\n",
            " [26.73]\n",
            " [26.73]\n",
            " [26.08]\n",
            " [25.78]\n",
            " [27.90]\n",
            " [27.95]\n",
            " [36.01]\n",
            " [37.26]\n",
            " [37.26]\n",
            " [37.26]\n",
            " [37.26]\n",
            " [37.26]\n",
            " [42.33]\n",
            " [42.92]\n",
            " [43.63]\n",
            " [41.84]\n",
            " [42.10]\n",
            " [47.65]\n",
            " [47.65]\n",
            " [54.56]\n",
            " [55.55]\n",
            " [54.83]\n",
            " [52.19]\n",
            " [54.68]\n",
            " [56.15]\n",
            " [64.86]\n",
            " [65.43]\n",
            " [64.86]\n",
            " [69.23]\n",
            " [79.53]\n",
            " [80.83]\n",
            " [90.44]\n",
            " [127.81]\n",
            " [123.00]\n",
            " [68.44]\n",
            " [92.25]\n",
            " [89.68]\n",
            " [92.15]\n",
            " [113.47]\n",
            " [113.93]\n",
            " [208.32]\n",
            " [188.59]\n",
            " [201.04]\n",
            " [228.29]\n",
            " [306.82]\n",
            " [153.25]\n",
            " [310.83]\n",
            " [269.64]\n",
            " [264.74]\n",
            " [225.50]\n",
            " [306.35]\n",
            " [270.32]\n",
            " [259.56]\n",
            " [300.87]\n",
            " [288.04]\n",
            " [281.49]\n",
            " [351.76]\n",
            " [412.26]\n",
            " [441.76]\n",
            " [583.27]\n",
            " [568.52]\n",
            " [660.90]\n",
            " [715.09]\n",
            " [778.53]\n",
            " [747.92]\n",
            " [806.07]\n",
            " [829.28]\n",
            " [836.82]\n",
            " [942.90]\n",
            " [1118.56]\n",
            " [1447.07]\n",
            " [1728.28]\n",
            " [1752.71]\n",
            " [1818.55]\n",
            " [2297.76]\n",
            " [11.58]\n",
            " [12.50]\n",
            " [14.15]\n",
            " [14.15]\n",
            " [14.51]\n",
            " [10.46]\n",
            " [10.46]\n",
            " [11.52]\n",
            " [10.81]\n",
            " [10.27]\n",
            " [10.27]\n",
            " [11.46]\n",
            " [12.37]\n",
            " [12.37]\n",
            " [12.37]\n",
            " [13.31]\n",
            " [13.31]\n",
            " [13.31]\n",
            " [11.21]\n",
            " [11.52]\n",
            " [12.35]\n",
            " [12.35]\n",
            " [12.04]\n",
            " [12.04]\n",
            " [12.04]\n",
            " [12.23]\n",
            " [12.23]\n",
            " [12.23]\n",
            " [12.35]\n",
            " [12.35]\n",
            " [14.35]\n",
            " [14.62]\n",
            " [14.62]\n",
            " [14.62]\n",
            " [14.62]\n",
            " [14.62]\n",
            " [13.51]\n",
            " [13.51]\n",
            " [13.51]\n",
            " [13.51]\n",
            " [13.51]\n",
            " [13.51]\n",
            " [15.26]\n",
            " [15.26]\n",
            " [15.26]\n",
            " [15.28]\n",
            " [15.28]\n",
            " [21.19]\n",
            " [29.89]\n",
            " [30.62]\n",
            " [29.00]\n",
            " [28.62]\n",
            " [26.77]\n",
            " [28.20]\n",
            " [28.20]\n",
            " [31.20]\n",
            " [32.36]\n",
            " [30.75]\n",
            " [31.13]\n",
            " [30.01]\n",
            " [30.94]\n",
            " [30.80]\n",
            " [29.58]\n",
            " [29.42]\n",
            " [32.12]\n",
            " [46.38]\n",
            " [43.06]\n",
            " [44.39]\n",
            " [46.95]\n",
            " [46.95]\n",
            " [68.97]\n",
            " [65.39]\n",
            " [65.39]\n",
            " [69.22]\n",
            " [85.35]\n",
            " [85.06]\n",
            " [122.53]\n",
            " [67.38]\n",
            " [66.41]\n",
            " [67.02]\n",
            " [60.88]\n",
            " [58.38]\n",
            " [62.38]\n",
            " [75.15]\n",
            " [72.66]\n",
            " [73.37]\n",
            " [83.17]\n",
            " [78.95]\n",
            " [75.75]\n",
            " [74.91]\n",
            " [75.94]\n",
            " [73.68]\n",
            " [70.72]\n",
            " [72.35]\n",
            " [72.35]\n",
            " [80.62]\n",
            " [91.69]\n",
            " [88.85]\n",
            " [87.03]\n",
            " [89.29]\n",
            " [88.93]\n",
            " [86.65]\n",
            " [88.77]\n",
            " [85.05]\n",
            " [79.97]\n",
            " [77.91]\n",
            " [78.67]\n",
            " [76.62]\n",
            " [82.99]\n",
            " [89.49]\n",
            " [100.26]\n",
            " [85.81]\n",
            " [86.18]\n",
            " [80.65]\n",
            " [81.91]\n",
            " [79.73]\n",
            " [77.33]\n",
            " [78.62]\n",
            " [50.61]\n",
            " [52.02]\n",
            " [67.70]\n",
            " [68.42]\n",
            " [70.12]\n",
            " [73.58]\n",
            " [73.45]\n",
            " [75.21]\n",
            " [77.14]\n",
            " [75.88]\n",
            " [74.63]\n",
            " [73.64]\n",
            " [97.75]\n",
            " [95.79]\n",
            " [88.52]\n",
            " [88.34]\n",
            " [99.31]\n",
            " [83.68]\n",
            " [84.03]\n",
            " [80.60]\n",
            " [80.14]\n",
            " [71.99]\n",
            " [71.99]\n",
            " [66.69]\n",
            " [56.49]\n",
            " [57.45]\n",
            " [59.85]\n",
            " [44.55]\n",
            " [45.08]\n",
            " [40.85]\n",
            " [38.97]\n",
            " [45.05]\n",
            " [52.67]\n",
            " [51.47]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncy0CeLoY-iX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be380705-5d63-4da0-c12c-7ac090373bdb"
      },
      "source": [
        "#@title Preprocess & split data for train model\n",
        "# Train, test split\n",
        "train_ratio = 0.8 #@param {type:\"number\"}\n",
        "if train_ratio < 0 or  train_ratio > 1:\n",
        "    train_ratio = 0.8\n",
        "n_data = len(X_data)\n",
        "n_train = int(train_ratio * n_data)\n",
        "n_test = n_data - n_train\n",
        "# Feature Scaling\n",
        "scale_method = \"MinMax\" #@param [\"None\", \"MinMax\"]\n",
        "\n",
        "X_train, y_train = X_data[: n_train], y_data[: n_train]\n",
        "X_test, y_test = X_data[n_train:], y_data[n_train:]\n",
        "if scale_method == 'MinMax':\n",
        "    sc_train = MinMaxScaler(feature_range = (0, 1))\n",
        "    X_train_scaled = sc_train.fit_transform(X_train.T).T\n",
        "    y_train_scaled = sc_train.transform(y_train.T).T\n",
        "    sc_test = MinMaxScaler(feature_range = (0, 1))\n",
        "    X_test_scaled = sc_test.fit_transform(X_test.T).T\n",
        "    y_test_scaled = sc_test.transform(y_test.T).T\n",
        "    # X_train, y_train = X_train_scaled, y_train_scaled\n",
        "    # X_test, y_test = X_test_scaled, y_test_scaled\n",
        "print(X_train.shape, y_train.shape)\n",
        "print(X_train_scaled.shape, y_train_scaled.shape)\n",
        "print(X_test.shape, y_test.shape)\n",
        "print(X_test_scaled.shape, y_test_scaled.shape)\n",
        "\n",
        "# print(X_train)\n",
        "# print(y_train)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(243, 30) (243, 1)\n",
            "(243, 30) (243, 1)\n",
            "(61, 30) (61, 1)\n",
            "(61, 30) (61, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s82DA41L_xiz"
      },
      "source": [
        "## LSTM model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZfyb31yHUi4"
      },
      "source": [
        "### Build model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oN8Yeavy-FV1"
      },
      "source": [
        "#@title Build & fit model\n",
        "lstm_units = 50 #@param {type:\"integer\"}\n",
        "dropout_prob = 0.5 #@param {type:\"number\"}\n",
        "epochs = 8000 #@param {type:\"integer\"}\n",
        "batch_size = 512 #@param {type:\"integer\"}\n",
        "\n",
        "model = Sequential()\n",
        "#Adding the first LSTM layer and some Dropout regularisation\n",
        "model.add(LSTM(units=lstm_units,\n",
        "               return_sequences=True,\n",
        "               input_shape=(X_data.shape[1], 1)))\n",
        "model.add(Dropout(dropout_prob))\n",
        "# Adding a second LSTM layer and some Dropout regularisation\n",
        "model.add(LSTM(units=lstm_units,\n",
        "               return_sequences=True))\n",
        "model.add(Dropout(dropout_prob))\n",
        "# Adding a third LSTM layer and some Dropout regularisation\n",
        "model.add(LSTM(units=lstm_units,\n",
        "               return_sequences=True))\n",
        "model.add(Dropout(dropout_prob))\n",
        "# Adding a fourth LSTM layer and some Dropout regularisation\n",
        "model.add(LSTM(units=lstm_units))\n",
        "model.add(Dropout(dropout_prob))\n",
        "# Adding the output layer\n",
        "model.add(Dense(units=1))\n",
        "\n",
        "# Adam optimizer\n",
        "opt = Adam(learning_rate=0.0005, epsilon=1e-06, decay=1e-06)\n",
        "# # PiecewiseConstantDecay optimizer\n",
        "# boundaries = [200, 800, 2000, 4000]\n",
        "# values = [0.01, 0.001, 0.0005, 0.0001, 0.00001]\n",
        "# opt = keras.optimizers.schedules.PiecewiseConstantDecay(\n",
        "#     boundaries, values)\n",
        "# Compiling the RNN\n",
        "# model.compile(optimizer = opt, loss = 'mean_squared_error')\n",
        "model.compile(optimizer = 'adam', loss = 'mean_squared_error')"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jin-QL3uXUOg"
      },
      "source": [
        "### Train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKDU7Oy3XXHQ",
        "outputId": "5b3d0db4-85e3-4840-eee2-29a224d76352"
      },
      "source": [
        "def train_lstm(model, X_train, y_train, epochs, batch_size):\n",
        "    # We have now reshaped the data into the following format (#values, #time-steps, #1 dimensional output).\n",
        "    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
        "    y_train = np.reshape(y_train, (y_train.shape[0], 1))\n",
        "\n",
        "    # Fitting the RNN to the Training set\n",
        "    model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size)\n",
        "    return model\n",
        "\n",
        "model = train_lstm(model, X_train_scaled, y_train_scaled, epochs, batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/8000\n",
            "1/1 [==============================] - 6s 6s/step - loss: 0.4691\n",
            "Epoch 2/8000\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.3959\n",
            "Epoch 3/8000\n",
            "1/1 [==============================] - 0s 179ms/step - loss: 0.3290\n",
            "Epoch 4/8000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.2658\n",
            "Epoch 5/8000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.2217\n",
            "Epoch 6/8000\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.2048\n",
            "Epoch 7/8000\n",
            "1/1 [==============================] - 0s 198ms/step - loss: 0.2342\n",
            "Epoch 8/8000\n",
            "1/1 [==============================] - 0s 199ms/step - loss: 0.2258\n",
            "Epoch 9/8000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.2105\n",
            "Epoch 10/8000\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 0.1885\n",
            "Epoch 11/8000\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 0.1874\n",
            "Epoch 12/8000\n",
            "1/1 [==============================] - 0s 199ms/step - loss: 0.1933\n",
            "Epoch 13/8000\n",
            "1/1 [==============================] - 0s 198ms/step - loss: 0.2001\n",
            "Epoch 14/8000\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 0.1998\n",
            "Epoch 15/8000\n",
            "1/1 [==============================] - 0s 197ms/step - loss: 0.1996\n",
            "Epoch 16/8000\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 0.1994\n",
            "Epoch 17/8000\n",
            "1/1 [==============================] - 0s 196ms/step - loss: 0.1870\n",
            "Epoch 18/8000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.1741\n",
            "Epoch 19/8000\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.1715\n",
            "Epoch 20/8000\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.1740\n",
            "Epoch 21/8000\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.1699\n",
            "Epoch 22/8000\n",
            "1/1 [==============================] - 0s 202ms/step - loss: 0.1746\n",
            "Epoch 23/8000\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 0.1701\n",
            "Epoch 24/8000\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.1815\n",
            "Epoch 25/8000\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 0.1796\n",
            "Epoch 26/8000\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 0.1712\n",
            "Epoch 27/8000\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 0.1812\n",
            "Epoch 28/8000\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.1761\n",
            "Epoch 29/8000\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 0.1642\n",
            "Epoch 30/8000\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 0.1670\n",
            "Epoch 31/8000\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 0.1617\n",
            "Epoch 32/8000\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 0.1741\n",
            "Epoch 33/8000\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 0.1612\n",
            "Epoch 34/8000\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 0.1638\n",
            "Epoch 35/8000\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 0.1701\n",
            "Epoch 36/8000\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 0.1646\n",
            "Epoch 37/8000\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 0.1575\n",
            "Epoch 38/8000\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.1625\n",
            "Epoch 39/8000\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 0.1682\n",
            "Epoch 40/8000\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.1618\n",
            "Epoch 41/8000\n",
            "1/1 [==============================] - 0s 203ms/step - loss: 0.1671\n",
            "Epoch 42/8000\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 0.1533\n",
            "Epoch 43/8000\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 0.1600\n",
            "Epoch 44/8000\n",
            "1/1 [==============================] - 0s 209ms/step - loss: 0.1552\n",
            "Epoch 45/8000\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 0.1514\n",
            "Epoch 46/8000\n",
            "1/1 [==============================] - 0s 179ms/step - loss: 0.1508\n",
            "Epoch 47/8000\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 0.1462\n",
            "Epoch 48/8000\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 0.1461\n",
            "Epoch 49/8000\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 0.1475\n",
            "Epoch 50/8000\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 0.1495\n",
            "Epoch 51/8000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.1500\n",
            "Epoch 52/8000\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 0.1514\n",
            "Epoch 53/8000\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 0.1411\n",
            "Epoch 54/8000\n",
            "1/1 [==============================] - 0s 195ms/step - loss: 0.1454\n",
            "Epoch 55/8000\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 0.1439\n",
            "Epoch 56/8000\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.1338\n",
            "Epoch 57/8000\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 0.1340\n",
            "Epoch 58/8000\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.1374\n",
            "Epoch 59/8000\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 0.1239\n",
            "Epoch 60/8000\n",
            "1/1 [==============================] - 0s 203ms/step - loss: 0.1215\n",
            "Epoch 61/8000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.1351\n",
            "Epoch 62/8000\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 0.1228\n",
            "Epoch 63/8000\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 0.1244\n",
            "Epoch 64/8000\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 0.1386\n",
            "Epoch 65/8000\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.1312\n",
            "Epoch 66/8000\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 0.1356\n",
            "Epoch 67/8000\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 0.1366\n",
            "Epoch 68/8000\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 0.1235\n",
            "Epoch 69/8000\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 0.1211\n",
            "Epoch 70/8000\n",
            "1/1 [==============================] - 0s 198ms/step - loss: 0.1207\n",
            "Epoch 71/8000\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 0.1306\n",
            "Epoch 72/8000\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.1236\n",
            "Epoch 73/8000\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.1259\n",
            "Epoch 74/8000\n",
            "1/1 [==============================] - 0s 179ms/step - loss: 0.1230\n",
            "Epoch 75/8000\n",
            "1/1 [==============================] - 0s 195ms/step - loss: 0.1301\n",
            "Epoch 76/8000\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 0.1221\n",
            "Epoch 77/8000\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 0.1266\n",
            "Epoch 78/8000\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.1199\n",
            "Epoch 79/8000\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.1276\n",
            "Epoch 80/8000\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 0.1219\n",
            "Epoch 81/8000\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 0.1206\n",
            "Epoch 82/8000\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 0.1255\n",
            "Epoch 83/8000\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 0.1274\n",
            "Epoch 84/8000\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 0.1285\n",
            "Epoch 85/8000\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 0.1257\n",
            "Epoch 86/8000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.1200\n",
            "Epoch 87/8000\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 0.1208\n",
            "Epoch 88/8000\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 0.1195\n",
            "Epoch 89/8000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.1241\n",
            "Epoch 90/8000\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 0.1256\n",
            "Epoch 91/8000\n",
            "1/1 [==============================] - 0s 195ms/step - loss: 0.1250\n",
            "Epoch 92/8000\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 0.1227\n",
            "Epoch 93/8000\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 0.1246\n",
            "Epoch 94/8000\n",
            "1/1 [==============================] - 0s 195ms/step - loss: 0.1269\n",
            "Epoch 95/8000\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 0.1211\n",
            "Epoch 96/8000\n",
            "1/1 [==============================] - 0s 179ms/step - loss: 0.1231\n",
            "Epoch 97/8000\n",
            "1/1 [==============================] - 0s 200ms/step - loss: 0.1225\n",
            "Epoch 98/8000\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 0.1230\n",
            "Epoch 99/8000\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 0.1222\n",
            "Epoch 100/8000\n",
            "1/1 [==============================] - 0s 208ms/step - loss: 0.1256\n",
            "Epoch 101/8000\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 0.1243\n",
            "Epoch 102/8000\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.1157\n",
            "Epoch 103/8000\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 0.1234\n",
            "Epoch 104/8000\n",
            "1/1 [==============================] - 0s 195ms/step - loss: 0.1219\n",
            "Epoch 105/8000\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 0.1231\n",
            "Epoch 106/8000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.1288\n",
            "Epoch 107/8000\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.1198\n",
            "Epoch 108/8000\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.1194\n",
            "Epoch 109/8000\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 0.1148\n",
            "Epoch 110/8000\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 0.1212\n",
            "Epoch 111/8000\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 0.1158\n",
            "Epoch 112/8000\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.1226\n",
            "Epoch 113/8000\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 0.1226\n",
            "Epoch 114/8000\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 0.1169\n",
            "Epoch 115/8000\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 0.1210\n",
            "Epoch 116/8000\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 0.1272\n",
            "Epoch 117/8000\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 0.1175\n",
            "Epoch 118/8000\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.1170\n",
            "Epoch 119/8000\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 0.1208\n",
            "Epoch 120/8000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.1201\n",
            "Epoch 121/8000\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 0.1198\n",
            "Epoch 122/8000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.1217\n",
            "Epoch 123/8000\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 0.1197\n",
            "Epoch 124/8000\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 0.1200\n",
            "Epoch 125/8000\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 0.1270\n",
            "Epoch 126/8000\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 0.1228\n",
            "Epoch 127/8000\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 0.1263\n",
            "Epoch 128/8000\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 0.1184\n",
            "Epoch 129/8000\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.1219\n",
            "Epoch 130/8000\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.1215\n",
            "Epoch 131/8000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.1270\n",
            "Epoch 132/8000\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 0.1256\n",
            "Epoch 133/8000\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.1244\n",
            "Epoch 134/8000\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 0.1214\n",
            "Epoch 135/8000\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.1180\n",
            "Epoch 136/8000\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 0.1214\n",
            "Epoch 137/8000\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.1210\n",
            "Epoch 138/8000\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 0.1243\n",
            "Epoch 139/8000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.1181\n",
            "Epoch 140/8000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.1205\n",
            "Epoch 141/8000\n",
            "1/1 [==============================] - 0s 196ms/step - loss: 0.1113\n",
            "Epoch 142/8000\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 0.1206\n",
            "Epoch 143/8000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.1162\n",
            "Epoch 144/8000\n",
            "1/1 [==============================] - 0s 196ms/step - loss: 0.1315\n",
            "Epoch 145/8000\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 0.1286\n",
            "Epoch 146/8000\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 0.1206\n",
            "Epoch 147/8000\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 0.1166\n",
            "Epoch 148/8000\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.1165\n",
            "Epoch 149/8000\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 0.1171\n",
            "Epoch 150/8000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.1221\n",
            "Epoch 151/8000\n",
            "1/1 [==============================] - 0s 196ms/step - loss: 0.1159\n",
            "Epoch 152/8000\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 0.1119\n",
            "Epoch 153/8000\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 0.1184\n",
            "Epoch 154/8000\n",
            "1/1 [==============================] - 0s 203ms/step - loss: 0.1189\n",
            "Epoch 155/8000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.1191\n",
            "Epoch 156/8000\n",
            "1/1 [==============================] - 0s 201ms/step - loss: 0.1135\n",
            "Epoch 157/8000\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 0.1215\n",
            "Epoch 158/8000\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 0.1185\n",
            "Epoch 159/8000\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.1100\n",
            "Epoch 160/8000\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 0.1127\n",
            "Epoch 161/8000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.1179\n",
            "Epoch 162/8000\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 0.1158\n",
            "Epoch 163/8000\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 0.1158\n",
            "Epoch 164/8000\n",
            "1/1 [==============================] - 0s 202ms/step - loss: 0.1184\n",
            "Epoch 165/8000\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.1126\n",
            "Epoch 166/8000\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.1097\n",
            "Epoch 167/8000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.1135\n",
            "Epoch 168/8000\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 0.1113\n",
            "Epoch 169/8000\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 0.1115\n",
            "Epoch 170/8000\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.1223\n",
            "Epoch 171/8000\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 0.1127\n",
            "Epoch 172/8000\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 0.1135\n",
            "Epoch 173/8000\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 0.1164\n",
            "Epoch 174/8000\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 0.1190\n",
            "Epoch 175/8000\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 0.1196\n",
            "Epoch 176/8000\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.1157\n",
            "Epoch 177/8000\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.1158\n",
            "Epoch 178/8000\n",
            "1/1 [==============================] - 0s 174ms/step - loss: 0.1159\n",
            "Epoch 179/8000\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 0.1077\n",
            "Epoch 180/8000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.1161\n",
            "Epoch 181/8000\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 0.1121\n",
            "Epoch 182/8000\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.1216\n",
            "Epoch 183/8000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.1152\n",
            "Epoch 184/8000\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 0.1080\n",
            "Epoch 185/8000\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.1188\n",
            "Epoch 186/8000\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.1085\n",
            "Epoch 187/8000\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.1103\n",
            "Epoch 188/8000\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 0.1197\n",
            "Epoch 189/8000\n",
            "1/1 [==============================] - 0s 198ms/step - loss: 0.1096\n",
            "Epoch 190/8000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.1120\n",
            "Epoch 191/8000\n",
            "1/1 [==============================] - 0s 195ms/step - loss: 0.1163\n",
            "Epoch 192/8000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.1116\n",
            "Epoch 193/8000\n",
            "1/1 [==============================] - 0s 195ms/step - loss: 0.1135\n",
            "Epoch 194/8000\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 0.1097\n",
            "Epoch 195/8000\n",
            "1/1 [==============================] - 0s 195ms/step - loss: 0.1098\n",
            "Epoch 196/8000\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 0.1110\n",
            "Epoch 197/8000\n",
            "1/1 [==============================] - 0s 205ms/step - loss: 0.1071\n",
            "Epoch 198/8000\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 0.1137\n",
            "Epoch 199/8000\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.1086\n",
            "Epoch 200/8000\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.1060\n",
            "Epoch 201/8000\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.1121\n",
            "Epoch 202/8000\n",
            "1/1 [==============================] - 0s 199ms/step - loss: 0.1127\n",
            "Epoch 203/8000\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 0.1063\n",
            "Epoch 204/8000\n",
            "1/1 [==============================] - 0s 196ms/step - loss: 0.1102\n",
            "Epoch 205/8000\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.1142\n",
            "Epoch 206/8000\n",
            "1/1 [==============================] - 0s 201ms/step - loss: 0.1134\n",
            "Epoch 207/8000\n",
            "1/1 [==============================] - 0s 209ms/step - loss: 0.1107\n",
            "Epoch 208/8000\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 0.1092\n",
            "Epoch 209/8000\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 0.1102\n",
            "Epoch 210/8000\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.1091\n",
            "Epoch 211/8000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.1101\n",
            "Epoch 212/8000\n",
            "1/1 [==============================] - 0s 209ms/step - loss: 0.1058\n",
            "Epoch 213/8000\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.1078\n",
            "Epoch 214/8000\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 0.1071\n",
            "Epoch 215/8000\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 0.1157\n",
            "Epoch 216/8000\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 0.1048\n",
            "Epoch 217/8000\n",
            "1/1 [==============================] - 0s 204ms/step - loss: 0.1048\n",
            "Epoch 218/8000\n",
            "1/1 [==============================] - 0s 179ms/step - loss: 0.1060\n",
            "Epoch 219/8000\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 0.1083\n",
            "Epoch 220/8000\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 0.1085\n",
            "Epoch 221/8000\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 0.1145\n",
            "Epoch 222/8000\n",
            "1/1 [==============================] - 0s 200ms/step - loss: 0.1108\n",
            "Epoch 223/8000\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 0.1076\n",
            "Epoch 224/8000\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.1058\n",
            "Epoch 225/8000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.1021\n",
            "Epoch 226/8000\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 0.1133\n",
            "Epoch 227/8000\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 0.1123\n",
            "Epoch 228/8000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.1047\n",
            "Epoch 229/8000\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 0.1042\n",
            "Epoch 230/8000\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.1114\n",
            "Epoch 231/8000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.1041\n",
            "Epoch 232/8000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.1119\n",
            "Epoch 233/8000\n",
            "1/1 [==============================] - 0s 196ms/step - loss: 0.1045\n",
            "Epoch 234/8000\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.0981\n",
            "Epoch 235/8000\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 0.1058\n",
            "Epoch 236/8000\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.1072\n",
            "Epoch 237/8000\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.1000\n",
            "Epoch 238/8000\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.1084\n",
            "Epoch 239/8000\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.1093\n",
            "Epoch 240/8000\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.0977\n",
            "Epoch 241/8000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.1032\n",
            "Epoch 242/8000\n",
            "1/1 [==============================] - 0s 198ms/step - loss: 0.1024\n",
            "Epoch 243/8000\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 0.1021\n",
            "Epoch 244/8000\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 0.1003\n",
            "Epoch 245/8000\n",
            "1/1 [==============================] - 0s 198ms/step - loss: 0.1029\n",
            "Epoch 246/8000\n",
            "1/1 [==============================] - 0s 198ms/step - loss: 0.1065\n",
            "Epoch 247/8000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.1060\n",
            "Epoch 248/8000\n",
            "1/1 [==============================] - 0s 195ms/step - loss: 0.1034\n",
            "Epoch 249/8000\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.1095\n",
            "Epoch 250/8000\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 0.0988\n",
            "Epoch 251/8000\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.1095\n",
            "Epoch 252/8000\n",
            "1/1 [==============================] - 0s 197ms/step - loss: 0.1013\n",
            "Epoch 253/8000\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 0.1053\n",
            "Epoch 254/8000\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.1004\n",
            "Epoch 255/8000\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.1107\n",
            "Epoch 256/8000\n",
            "1/1 [==============================] - 0s 202ms/step - loss: 0.1093\n",
            "Epoch 257/8000\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 0.1026\n",
            "Epoch 258/8000\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.1012\n",
            "Epoch 259/8000\n",
            "1/1 [==============================] - 0s 213ms/step - loss: 0.0966\n",
            "Epoch 260/8000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.1082\n",
            "Epoch 261/8000\n",
            "1/1 [==============================] - 0s 197ms/step - loss: 0.0996\n",
            "Epoch 262/8000\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.1001\n",
            "Epoch 263/8000\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.0982\n",
            "Epoch 264/8000\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 0.1058\n",
            "Epoch 265/8000\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 0.0978\n",
            "Epoch 266/8000\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.1044\n",
            "Epoch 267/8000\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.1039\n",
            "Epoch 268/8000\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 0.0974\n",
            "Epoch 269/8000\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 0.1051\n",
            "Epoch 270/8000\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 0.1098\n",
            "Epoch 271/8000\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.1055\n",
            "Epoch 272/8000\n",
            "1/1 [==============================] - 0s 197ms/step - loss: 0.1027\n",
            "Epoch 273/8000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.0999\n",
            "Epoch 274/8000\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 0.1085\n",
            "Epoch 275/8000\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 0.1099\n",
            "Epoch 276/8000\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.1010\n",
            "Epoch 277/8000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.1028\n",
            "Epoch 278/8000\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 0.0950\n",
            "Epoch 279/8000\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.0995\n",
            "Epoch 280/8000\n",
            "1/1 [==============================] - 0s 199ms/step - loss: 0.1033\n",
            "Epoch 281/8000\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.0989\n",
            "Epoch 282/8000\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 0.1037\n",
            "Epoch 283/8000\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 0.0945\n",
            "Epoch 284/8000\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.1023\n",
            "Epoch 285/8000\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.1055\n",
            "Epoch 286/8000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.0992\n",
            "Epoch 287/8000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.0990\n",
            "Epoch 288/8000\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.0947\n",
            "Epoch 289/8000\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 0.1003\n",
            "Epoch 290/8000\n",
            "1/1 [==============================] - 0s 198ms/step - loss: 0.0970\n",
            "Epoch 291/8000\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 0.1041\n",
            "Epoch 292/8000\n",
            "1/1 [==============================] - 0s 199ms/step - loss: 0.1008\n",
            "Epoch 293/8000\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 0.0935\n",
            "Epoch 294/8000\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.0994\n",
            "Epoch 295/8000\n",
            "1/1 [==============================] - 0s 195ms/step - loss: 0.0960\n",
            "Epoch 296/8000\n",
            "1/1 [==============================] - 0s 197ms/step - loss: 0.0983\n",
            "Epoch 297/8000\n",
            "1/1 [==============================] - 0s 197ms/step - loss: 0.0965\n",
            "Epoch 298/8000\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.0957\n",
            "Epoch 299/8000\n",
            "1/1 [==============================] - 0s 198ms/step - loss: 0.0962\n",
            "Epoch 300/8000\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 0.0987\n",
            "Epoch 301/8000\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 0.0954\n",
            "Epoch 302/8000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.0964\n",
            "Epoch 303/8000\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.0998\n",
            "Epoch 304/8000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.1001\n",
            "Epoch 305/8000\n",
            "1/1 [==============================] - 0s 201ms/step - loss: 0.0944\n",
            "Epoch 306/8000\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 0.0957\n",
            "Epoch 307/8000\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.0998\n",
            "Epoch 308/8000\n",
            "1/1 [==============================] - 0s 198ms/step - loss: 0.1037\n",
            "Epoch 309/8000\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 0.0971\n",
            "Epoch 310/8000\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 0.1024\n",
            "Epoch 311/8000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.1045\n",
            "Epoch 312/8000\n",
            "1/1 [==============================] - 0s 209ms/step - loss: 0.1108\n",
            "Epoch 313/8000\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 0.1027\n",
            "Epoch 314/8000\n",
            "1/1 [==============================] - 0s 200ms/step - loss: 0.1032\n",
            "Epoch 315/8000\n",
            "1/1 [==============================] - 0s 195ms/step - loss: 0.1021\n",
            "Epoch 316/8000\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 0.1037\n",
            "Epoch 317/8000\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 0.0939\n",
            "Epoch 318/8000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.1022\n",
            "Epoch 319/8000\n",
            "1/1 [==============================] - 0s 204ms/step - loss: 0.0993\n",
            "Epoch 320/8000\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 0.0992\n",
            "Epoch 321/8000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.1018\n",
            "Epoch 322/8000\n",
            "1/1 [==============================] - 0s 200ms/step - loss: 0.1038\n",
            "Epoch 323/8000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.0933\n",
            "Epoch 324/8000\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 0.0945\n",
            "Epoch 325/8000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.0962\n",
            "Epoch 326/8000\n",
            "1/1 [==============================] - 0s 206ms/step - loss: 0.0999\n",
            "Epoch 327/8000\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 0.0959\n",
            "Epoch 328/8000\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 0.1027\n",
            "Epoch 329/8000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.1010\n",
            "Epoch 330/8000\n",
            "1/1 [==============================] - 0s 218ms/step - loss: 0.0931\n",
            "Epoch 331/8000\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 0.1067\n",
            "Epoch 332/8000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.0957\n",
            "Epoch 333/8000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.1021\n",
            "Epoch 334/8000\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 0.0955\n",
            "Epoch 335/8000\n",
            "1/1 [==============================] - 0s 205ms/step - loss: 0.0912\n",
            "Epoch 336/8000\n",
            "1/1 [==============================] - 0s 198ms/step - loss: 0.0964\n",
            "Epoch 337/8000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.0987\n",
            "Epoch 338/8000\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 0.1020\n",
            "Epoch 339/8000\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 0.1062\n",
            "Epoch 340/8000\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 0.1025\n",
            "Epoch 341/8000\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.0921\n",
            "Epoch 342/8000\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.0993\n",
            "Epoch 343/8000\n",
            "1/1 [==============================] - 0s 195ms/step - loss: 0.1119\n",
            "Epoch 344/8000\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 0.0920\n",
            "Epoch 345/8000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.0991\n",
            "Epoch 346/8000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.0954\n",
            "Epoch 347/8000\n",
            "1/1 [==============================] - 0s 197ms/step - loss: 0.1007\n",
            "Epoch 348/8000\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 0.0931\n",
            "Epoch 349/8000\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 0.0978\n",
            "Epoch 350/8000\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.0991\n",
            "Epoch 351/8000\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 0.0940\n",
            "Epoch 352/8000\n",
            "1/1 [==============================] - 0s 198ms/step - loss: 0.0894\n",
            "Epoch 353/8000\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 0.0936\n",
            "Epoch 354/8000\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 0.0944\n",
            "Epoch 355/8000\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 0.0925\n",
            "Epoch 356/8000\n",
            "1/1 [==============================] - 0s 179ms/step - loss: 0.0924\n",
            "Epoch 357/8000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.0911\n",
            "Epoch 358/8000\n",
            "1/1 [==============================] - 0s 196ms/step - loss: 0.0901\n",
            "Epoch 359/8000\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 0.0973\n",
            "Epoch 360/8000\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 0.1011\n",
            "Epoch 361/8000\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 0.0987\n",
            "Epoch 362/8000\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 0.0950\n",
            "Epoch 363/8000\n",
            "1/1 [==============================] - 0s 197ms/step - loss: 0.0957\n",
            "Epoch 364/8000\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.0958\n",
            "Epoch 365/8000\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 0.0936\n",
            "Epoch 366/8000\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 0.0934\n",
            "Epoch 367/8000\n",
            "1/1 [==============================] - 0s 198ms/step - loss: 0.0969\n",
            "Epoch 368/8000\n",
            "1/1 [==============================] - 0s 199ms/step - loss: 0.0952\n",
            "Epoch 369/8000\n",
            "1/1 [==============================] - 0s 179ms/step - loss: 0.0934\n",
            "Epoch 370/8000\n",
            "1/1 [==============================] - 0s 201ms/step - loss: 0.0941\n",
            "Epoch 371/8000\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 0.1032\n",
            "Epoch 372/8000\n",
            "1/1 [==============================] - 0s 197ms/step - loss: 0.0914\n",
            "Epoch 373/8000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.0914\n",
            "Epoch 374/8000\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.0940\n",
            "Epoch 375/8000\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 0.0933\n",
            "Epoch 376/8000\n",
            "1/1 [==============================] - 0s 195ms/step - loss: 0.0946\n",
            "Epoch 377/8000\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 0.0930\n",
            "Epoch 378/8000\n",
            "1/1 [==============================] - 0s 204ms/step - loss: 0.0936\n",
            "Epoch 379/8000\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 0.0879\n",
            "Epoch 380/8000\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.0978\n",
            "Epoch 381/8000\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.0882\n",
            "Epoch 382/8000\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 0.0921\n",
            "Epoch 383/8000\n",
            "1/1 [==============================] - 0s 198ms/step - loss: 0.0959\n",
            "Epoch 384/8000\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.0954\n",
            "Epoch 385/8000\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.0943\n",
            "Epoch 386/8000\n",
            "1/1 [==============================] - 0s 179ms/step - loss: 0.0980\n",
            "Epoch 387/8000\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 0.0937\n",
            "Epoch 388/8000\n",
            "1/1 [==============================] - 0s 205ms/step - loss: 0.0868\n",
            "Epoch 389/8000\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 0.0901\n",
            "Epoch 390/8000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.0944\n",
            "Epoch 391/8000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.0885\n",
            "Epoch 392/8000\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 0.0872\n",
            "Epoch 393/8000\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 0.1008\n",
            "Epoch 394/8000\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 0.0967\n",
            "Epoch 395/8000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.0918\n",
            "Epoch 396/8000\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.1006\n",
            "Epoch 397/8000\n",
            "1/1 [==============================] - 0s 195ms/step - loss: 0.0896\n",
            "Epoch 398/8000\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 0.0966\n",
            "Epoch 399/8000\n",
            "1/1 [==============================] - 0s 203ms/step - loss: 0.0954\n",
            "Epoch 400/8000\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.0896\n",
            "Epoch 401/8000\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 0.0855\n",
            "Epoch 402/8000\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.0912\n",
            "Epoch 403/8000\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 0.0942\n",
            "Epoch 404/8000\n",
            "1/1 [==============================] - 0s 201ms/step - loss: 0.0941\n",
            "Epoch 405/8000\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 0.0938\n",
            "Epoch 406/8000\n",
            "1/1 [==============================] - 0s 204ms/step - loss: 0.0924\n",
            "Epoch 407/8000\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.0972\n",
            "Epoch 408/8000\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 0.0898\n",
            "Epoch 409/8000\n",
            "1/1 [==============================] - 0s 200ms/step - loss: 0.0936\n",
            "Epoch 410/8000\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 0.0930\n",
            "Epoch 411/8000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.0840\n",
            "Epoch 412/8000\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 0.0907\n",
            "Epoch 413/8000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.0937\n",
            "Epoch 414/8000\n",
            "1/1 [==============================] - 0s 207ms/step - loss: 0.0968\n",
            "Epoch 415/8000\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 0.0961\n",
            "Epoch 416/8000\n",
            "1/1 [==============================] - 0s 199ms/step - loss: 0.0882\n",
            "Epoch 417/8000\n",
            "1/1 [==============================] - 0s 201ms/step - loss: 0.0871\n",
            "Epoch 418/8000\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 0.0882\n",
            "Epoch 419/8000\n",
            "1/1 [==============================] - 0s 197ms/step - loss: 0.1018\n",
            "Epoch 420/8000\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.0915\n",
            "Epoch 421/8000\n",
            "1/1 [==============================] - 0s 201ms/step - loss: 0.0862\n",
            "Epoch 422/8000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.0905\n",
            "Epoch 423/8000\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.0902\n",
            "Epoch 424/8000\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 0.0925\n",
            "Epoch 425/8000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.0869\n",
            "Epoch 426/8000\n",
            "1/1 [==============================] - 0s 204ms/step - loss: 0.0940\n",
            "Epoch 427/8000\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 0.0881\n",
            "Epoch 428/8000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.0944\n",
            "Epoch 429/8000\n",
            "1/1 [==============================] - 0s 206ms/step - loss: 0.0896\n",
            "Epoch 430/8000\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 0.0911\n",
            "Epoch 431/8000\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.0970\n",
            "Epoch 432/8000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.0900\n",
            "Epoch 433/8000\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.0912\n",
            "Epoch 434/8000\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.0891\n",
            "Epoch 435/8000\n",
            "1/1 [==============================] - 0s 224ms/step - loss: 0.0881\n",
            "Epoch 436/8000\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 0.0927\n",
            "Epoch 437/8000\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.0924\n",
            "Epoch 438/8000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.0928\n",
            "Epoch 439/8000\n",
            "1/1 [==============================] - 0s 195ms/step - loss: 0.0950\n",
            "Epoch 440/8000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.0878\n",
            "Epoch 441/8000\n",
            "1/1 [==============================] - 0s 203ms/step - loss: 0.0952\n",
            "Epoch 442/8000\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 0.1038\n",
            "Epoch 443/8000\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 0.0978\n",
            "Epoch 444/8000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.0885\n",
            "Epoch 445/8000\n",
            "1/1 [==============================] - 0s 199ms/step - loss: 0.0847\n",
            "Epoch 446/8000\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.0889\n",
            "Epoch 447/8000\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.0929\n",
            "Epoch 448/8000\n",
            "1/1 [==============================] - 0s 198ms/step - loss: 0.0889\n",
            "Epoch 449/8000\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 0.0893\n",
            "Epoch 450/8000\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.0855\n",
            "Epoch 451/8000\n",
            "1/1 [==============================] - 0s 200ms/step - loss: 0.0991\n",
            "Epoch 452/8000\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.0903\n",
            "Epoch 453/8000\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 0.0830\n",
            "Epoch 454/8000\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.0886\n",
            "Epoch 455/8000\n",
            "1/1 [==============================] - 0s 200ms/step - loss: 0.0900\n",
            "Epoch 456/8000\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.0932\n",
            "Epoch 457/8000\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.0918\n",
            "Epoch 458/8000\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.0887\n",
            "Epoch 459/8000\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.0875\n",
            "Epoch 460/8000\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.0892\n",
            "Epoch 461/8000\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 0.0835\n",
            "Epoch 462/8000\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.0849\n",
            "Epoch 463/8000\n",
            "1/1 [==============================] - 0s 199ms/step - loss: 0.0836\n",
            "Epoch 464/8000\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.0896\n",
            "Epoch 465/8000\n",
            "1/1 [==============================] - 0s 200ms/step - loss: 0.0887\n",
            "Epoch 466/8000\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 0.0857\n",
            "Epoch 467/8000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.0847\n",
            "Epoch 468/8000\n",
            "1/1 [==============================] - 0s 195ms/step - loss: 0.0915\n",
            "Epoch 469/8000\n",
            "1/1 [==============================] - 0s 196ms/step - loss: 0.0854\n",
            "Epoch 470/8000\n",
            "1/1 [==============================] - 0s 226ms/step - loss: 0.0881\n",
            "Epoch 471/8000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.0837\n",
            "Epoch 472/8000\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.0877\n",
            "Epoch 473/8000\n",
            "1/1 [==============================] - 0s 202ms/step - loss: 0.0802\n",
            "Epoch 474/8000\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.0903\n",
            "Epoch 475/8000\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.0849\n",
            "Epoch 476/8000\n",
            "1/1 [==============================] - 0s 195ms/step - loss: 0.0877\n",
            "Epoch 477/8000\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 0.0861\n",
            "Epoch 478/8000\n",
            "1/1 [==============================] - 0s 195ms/step - loss: 0.0877\n",
            "Epoch 479/8000\n",
            "1/1 [==============================] - 0s 195ms/step - loss: 0.0883\n",
            "Epoch 480/8000\n",
            "1/1 [==============================] - 0s 207ms/step - loss: 0.0875\n",
            "Epoch 481/8000\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 0.0826\n",
            "Epoch 482/8000\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 0.0805\n",
            "Epoch 483/8000\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.0916\n",
            "Epoch 484/8000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.0870\n",
            "Epoch 485/8000\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 0.0842\n",
            "Epoch 486/8000\n",
            "1/1 [==============================] - 0s 204ms/step - loss: 0.0857\n",
            "Epoch 487/8000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.0914\n",
            "Epoch 488/8000\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 0.0796\n",
            "Epoch 489/8000\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.0872\n",
            "Epoch 490/8000\n",
            "1/1 [==============================] - 0s 197ms/step - loss: 0.0824\n",
            "Epoch 491/8000\n",
            "1/1 [==============================] - 0s 198ms/step - loss: 0.0872\n",
            "Epoch 492/8000\n",
            "1/1 [==============================] - 0s 200ms/step - loss: 0.0844\n",
            "Epoch 493/8000\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 0.0980\n",
            "Epoch 494/8000\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.0874\n",
            "Epoch 495/8000\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.0875\n",
            "Epoch 496/8000\n",
            "1/1 [==============================] - 0s 196ms/step - loss: 0.0837\n",
            "Epoch 497/8000\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 0.0886\n",
            "Epoch 498/8000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.0852\n",
            "Epoch 499/8000\n",
            "1/1 [==============================] - 0s 204ms/step - loss: 0.0846\n",
            "Epoch 500/8000\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 0.0856\n",
            "Epoch 501/8000\n",
            "1/1 [==============================] - 0s 205ms/step - loss: 0.0873\n",
            "Epoch 502/8000\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 0.0838\n",
            "Epoch 503/8000\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.0813\n",
            "Epoch 504/8000\n",
            "1/1 [==============================] - 0s 197ms/step - loss: 0.0820\n",
            "Epoch 505/8000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.0845\n",
            "Epoch 506/8000\n",
            "1/1 [==============================] - 0s 195ms/step - loss: 0.0766\n",
            "Epoch 507/8000\n",
            "1/1 [==============================] - 0s 203ms/step - loss: 0.0863\n",
            "Epoch 508/8000\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 0.0850\n",
            "Epoch 509/8000\n",
            "1/1 [==============================] - 0s 195ms/step - loss: 0.0892\n",
            "Epoch 510/8000\n",
            "1/1 [==============================] - 0s 201ms/step - loss: 0.0830\n",
            "Epoch 511/8000\n",
            "1/1 [==============================] - 0s 206ms/step - loss: 0.0795\n",
            "Epoch 512/8000\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 0.0861\n",
            "Epoch 513/8000\n",
            "1/1 [==============================] - 0s 200ms/step - loss: 0.0819\n",
            "Epoch 514/8000\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 0.0864\n",
            "Epoch 515/8000\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.0852\n",
            "Epoch 516/8000\n",
            "1/1 [==============================] - 0s 201ms/step - loss: 0.0826\n",
            "Epoch 517/8000\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.0817\n",
            "Epoch 518/8000\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.0803\n",
            "Epoch 519/8000\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.0838\n",
            "Epoch 520/8000\n",
            "1/1 [==============================] - 0s 202ms/step - loss: 0.0797\n",
            "Epoch 521/8000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.0875\n",
            "Epoch 522/8000\n",
            "1/1 [==============================] - 0s 196ms/step - loss: 0.0800\n",
            "Epoch 523/8000\n",
            "1/1 [==============================] - 0s 195ms/step - loss: 0.0811\n",
            "Epoch 524/8000\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.0826\n",
            "Epoch 525/8000\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.0765\n",
            "Epoch 526/8000\n",
            "1/1 [==============================] - 0s 199ms/step - loss: 0.0832\n",
            "Epoch 527/8000\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 0.0778\n",
            "Epoch 528/8000\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 0.0773\n",
            "Epoch 529/8000\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.0755\n",
            "Epoch 530/8000\n",
            "1/1 [==============================] - 0s 207ms/step - loss: 0.0828\n",
            "Epoch 531/8000\n",
            "1/1 [==============================] - 0s 199ms/step - loss: 0.0762\n",
            "Epoch 532/8000\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.0756\n",
            "Epoch 533/8000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.0830\n",
            "Epoch 534/8000\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 0.0809\n",
            "Epoch 535/8000\n",
            "1/1 [==============================] - 0s 199ms/step - loss: 0.0802\n",
            "Epoch 536/8000\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.0786\n",
            "Epoch 537/8000\n",
            "1/1 [==============================] - 0s 207ms/step - loss: 0.0809\n",
            "Epoch 538/8000\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.0767\n",
            "Epoch 539/8000\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.0778\n",
            "Epoch 540/8000\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.0755\n",
            "Epoch 541/8000\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 0.0782\n",
            "Epoch 542/8000\n",
            "1/1 [==============================] - 0s 196ms/step - loss: 0.0826\n",
            "Epoch 543/8000\n",
            "1/1 [==============================] - 0s 197ms/step - loss: 0.0832\n",
            "Epoch 544/8000\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 0.0805\n",
            "Epoch 545/8000\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.0795\n",
            "Epoch 546/8000\n",
            "1/1 [==============================] - 0s 198ms/step - loss: 0.0808\n",
            "Epoch 547/8000\n",
            "1/1 [==============================] - 0s 203ms/step - loss: 0.0840\n",
            "Epoch 548/8000\n",
            "1/1 [==============================] - 0s 202ms/step - loss: 0.0822\n",
            "Epoch 549/8000\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 0.0717\n",
            "Epoch 550/8000\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 0.0787\n",
            "Epoch 551/8000\n",
            "1/1 [==============================] - 0s 195ms/step - loss: 0.0838\n",
            "Epoch 552/8000\n",
            "1/1 [==============================] - 0s 196ms/step - loss: 0.0772\n",
            "Epoch 553/8000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.0810\n",
            "Epoch 554/8000\n",
            "1/1 [==============================] - 0s 197ms/step - loss: 0.0766\n",
            "Epoch 555/8000\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 0.0773\n",
            "Epoch 556/8000\n",
            "1/1 [==============================] - 0s 201ms/step - loss: 0.0775\n",
            "Epoch 557/8000\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.0752\n",
            "Epoch 558/8000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.0713\n",
            "Epoch 559/8000\n",
            "1/1 [==============================] - 0s 199ms/step - loss: 0.0753\n",
            "Epoch 560/8000\n",
            "1/1 [==============================] - 0s 199ms/step - loss: 0.0763\n",
            "Epoch 561/8000\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 0.0728\n",
            "Epoch 562/8000\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.0740\n",
            "Epoch 563/8000\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.0777\n",
            "Epoch 564/8000\n",
            "1/1 [==============================] - 0s 199ms/step - loss: 0.0813\n",
            "Epoch 565/8000\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 0.0704\n",
            "Epoch 566/8000\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 0.0736\n",
            "Epoch 567/8000\n",
            "1/1 [==============================] - 0s 197ms/step - loss: 0.0789\n",
            "Epoch 568/8000\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 0.0794\n",
            "Epoch 569/8000\n",
            "1/1 [==============================] - 0s 197ms/step - loss: 0.0742\n",
            "Epoch 570/8000\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 0.0791\n",
            "Epoch 571/8000\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.0811\n",
            "Epoch 572/8000\n",
            "1/1 [==============================] - 0s 204ms/step - loss: 0.0737\n",
            "Epoch 573/8000\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 0.0734\n",
            "Epoch 574/8000\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 0.0736\n",
            "Epoch 575/8000\n",
            "1/1 [==============================] - 0s 223ms/step - loss: 0.0802\n",
            "Epoch 576/8000\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 0.0833\n",
            "Epoch 577/8000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OazllwgwAK7D"
      },
      "source": [
        "### Test model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeeHAryE_2Y9"
      },
      "source": [
        "# X_test = X_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b50yUip0AQwQ"
      },
      "source": [
        "predicted_stock_price = model.predict(np.reshape(X_test_scaled, (X_test_scaled.shape[0], X_test_scaled.shape[1], 1)))\n",
        "if scale_method == 'MinMax':\n",
        "    predicted_stock_price = sc_test.inverse_transform(predicted_stock_price.T).T\n",
        "    # y_test = sc_test.inverse_transform(y_test.T).T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWVeRc87ARJ3"
      },
      "source": [
        "y_test, predicted_stock_price"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmLg6t7dAZF5"
      },
      "source": [
        "float_formatter = \"{:.2f}\".format\n",
        "np.set_printoptions(formatter={'float_kind':float_formatter})\n",
        "print(y_test - predicted_stock_price)\n",
        "print(max(abs(y_test - predicted_stock_price)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTeRsDeZit4J"
      },
      "source": [
        "# Calculate RMSE and MAPE\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "def get_mape(y_true, y_pred): \n",
        "    \"\"\"\n",
        "    Compute mean absolute percentage error (MAPE)\n",
        "    \"\"\"\n",
        "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
        "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
        "\n",
        "rmse = math.sqrt(mean_squared_error(y_test, predicted_stock_price))\n",
        "mape = get_mape(y_test, predicted_stock_price)\n",
        "\n",
        "rmse, mape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0afd3y3LRMmU"
      },
      "source": [
        "# Visualising the results\n",
        "plt.figure(figsize=(20, 10), dpi= 120, facecolor='w', edgecolor='k')\n",
        "plt.plot(range(len(y_test)), y_test, 'o', color = 'red', label = 'y test groundtruth')\n",
        "plt.plot(range(len(y_test)), predicted_stock_price, 'o', color = 'blue', label = 'Predicted Price')\n",
        "plt.vlines(range(len(y_test)), np.minimum(y_test, predicted_stock_price), np.maximum(y_test, predicted_stock_price))\n",
        "# plt.xticks(np.arange(0,459,50))\n",
        "plt.title('LSTM Price Prediction')\n",
        "plt.xlabel('Sample id')\n",
        "plt.ylabel('Stock Price')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99ue3zEa4tqi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s89wSFWRG0If"
      },
      "source": [
        "## XGBoost model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wyj7ERelHsdv"
      },
      "source": [
        "### Build model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJul8GFRbV6b"
      },
      "source": [
        "#@title Build model\n",
        "seed = 100 #@param {type:\"integer\"}\n",
        "n_estimators = 100 #@param {type:\"integer\"}\n",
        "max_depth = 3 #@param {type:\"integer\"}\n",
        "learning_rate = 0.1 #@param {type:\"number\"}\n",
        "min_child_weight = 0 #@param {type:\"number\"}\n",
        "subsample = 1 #@param {type:\"number\"}\n",
        "colsample_bytree = 1 #@param {type:\"number\"}\n",
        "colsample_bylevel = 1 #@param {type:\"number\"}\n",
        "gamma = 0 #@param {type:\"number\"}\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "xgbmodel = XGBRegressor(seed=seed,\n",
        "                        n_estimators=n_estimators,\n",
        "                        max_depth=max_depth,\n",
        "                        learning_rate=learning_rate,\n",
        "                        min_child_weight=min_child_weight,\n",
        "                        subsample=subsample,\n",
        "                        colsample_bytree=colsample_bytree,\n",
        "                        colsample_bylevel=colsample_bylevel,\n",
        "                        gamma=gamma)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "raMH4SDILQg5"
      },
      "source": [
        "### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdKqzd_pHq2U"
      },
      "source": [
        "xgbmodel.fit(np.reshape(X_train_scaled, (X_train_scaled.shape[0], X_train_scaled.shape[1])), np.reshape(y_train_scaled, (y_train_scaled.shape[0])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AK8mFeHhLlPP"
      },
      "source": [
        "### Test model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0U2JZJTLm35"
      },
      "source": [
        "predicted_stock_price = xgbmodel.predict(np.reshape(X_test_scaled, (X_test_scaled.shape[0], X_test_scaled.shape[1])))\n",
        "predicted_stock_price = np.reshape(predicted_stock_price, (predicted_stock_price.shape[0], 1))\n",
        "if scale_method == 'MinMax':\n",
        "    predicted_stock_price = sc_test.inverse_transform(predicted_stock_price.T).T\n",
        "    # y_test = sc_test.inverse_transform(y_test.T).T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avLgZlNwLzbL"
      },
      "source": [
        "float_formatter = \"{:.2f}\".format\n",
        "np.set_printoptions(formatter={'float_kind':float_formatter})\n",
        "print(y_test - predicted_stock_price)\n",
        "print(max(abs(y_test - predicted_stock_price)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0_KL2VEbUea"
      },
      "source": [
        "rmse = math.sqrt(mean_squared_error(y_test, predicted_stock_price))\n",
        "mape = get_mape(y_test, predicted_stock_price)\n",
        "\n",
        "rmse, mape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F94dhXY7L3yG"
      },
      "source": [
        "# Visualising the results\n",
        "plt.figure(figsize=(20, 10), dpi= 120, facecolor='w', edgecolor='k')\n",
        "plt.plot(range(len(y_test)), y_test, 'o', color = 'red', label = 'y test groundtruth')\n",
        "plt.plot(range(len(y_test)), predicted_stock_price, 'o', color = 'blue', label = 'Predicted Price')\n",
        "plt.vlines(range(len(y_test)), np.minimum(y_test, predicted_stock_price), np.maximum(y_test, predicted_stock_price))\n",
        "# plt.xticks(np.arange(0,459,50))\n",
        "plt.title('XGBoost Price Prediction')\n",
        "plt.xlabel('Sample id')\n",
        "plt.ylabel('Stock Price')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RO0a4yUtMH8i"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}